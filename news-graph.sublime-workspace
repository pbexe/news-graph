{
	"auto_complete":
	{
		"selected_items":
		[
			[
				"p_",
				"p_neg_sentiment"
			],
			[
				"prin",
				"printByte"
			],
			[
				"pri",
				"printByte"
			],
			[
				"pr",
				"printByte"
			],
			[
				"print",
				"printNumber"
			],
			[
				"node",
				"node_sentiment"
			],
			[
				"m",
				"mfloat\tfloatfield"
			],
			[
				"sent",
				"sentiment"
			],
			[
				"top",
				"top_level_comment"
			],
			[
				"submi",
				"submission_sentiment"
			],
			[
				"if",
				"ifmain\tif __name__ == '__main__'"
			],
			[
				"in",
				"incorrect"
			],
			[
				"s",
				"sentence"
			],
			[
				"stop",
				"stop_words"
			],
			[
				"sop",
				"stop_words"
			],
			[
				"def",
				"def\tFunction"
			],
			[
				"le",
				"lexicon_frequency"
			],
			[
				"p",
				"p_neg_sentiment"
			],
			[
				"neg",
				"neg_lex"
			],
			[
				"pos",
				"pos_lex"
			],
			[
				"p_n",
				"p_neg_sentiment"
			],
			[
				"p_neg",
				"p_neg"
			],
			[
				"p_pos",
				"p_pos_sentiment"
			],
			[
				"lex",
				"lexicon"
			],
			[
				"lexicon",
				"lexicon_frequency"
			],
			[
				"font",
				"font-size"
			]
		]
	},
	"buffers":
	[
		{
			"contents": "\"\"\"Summary\nGenerates the contents of the database from reddit submissions.\n\nAttributes:\n    neg_lex (dict): Lexicon of negative sentiment and relative frequencies.\n    pos_lex (dict): Lexicon of negative sentiment and relative frequencies.\n    r (obj): Object used to interact with reddit. See https://pypi.python.org/pypi/praw\n\"\"\"\n\nimport os\nimport django\nfrom django.utils import timezone\nimport nltk\nimport praw\nfrom sentiment import naivebayes\nfrom praw.models import MoreComments\nfrom tqdm import tqdm\nimport string\nos.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"newsgraph.settings\")\ndjango.setup()\nfrom relationships.models import Story, Node, Edge, Sentiment\n\n\npos_lex = naivebayes.generate('sentiment/pos.txt', naivebayes.lexicon())\nneg_lex = naivebayes.generate('sentiment/neg.txt', naivebayes.lexicon())\nr = praw.Reddit(client_id='l-Gz5blkt7GCUg',\n                client_secret='_xLEgNing89k6__sWItU1_j9aR8',\n                user_agent='testscript by /u/pbexe')\n\n\ndef submission_sentiment(id):\n\n    \"\"\"Summary\n    Generate sentiment of specified reddit article.\n\n    Args:\n        id (int): Description\n\n    Returns:\n        float: Average sentiment of the article\n    \"\"\"\n\n    total = 0\n    n = 0\n    submission = r.submission(id)\n    for top_level_comment in submission.comments:\n        n += 1\n        if isinstance(top_level_comment, MoreComments):\n            continue\n        total += naivebayes.sentiment(top_level_comment.body, pos_lex, neg_lex)\n        return total / n\n\n\ndef stories():\n\n    \"\"\"Summary\n    Yields top and hot stories from the news and worldnews subreddits.\n\n    Returns:\n        tuple: Meta data for a news story\n    \"\"\"\n\n    stories = []\n    subreddits = ['news', 'worldnews']\n    for subreddit in subreddits:\n        submissions = r.subreddit(subreddit).top(limit=100)\n        for item in tqdm(submissions):\n            sentiment = submission_sentiment(item.id)\n            print(sentiment)\n            stories.append((item.url, item.title, sentiment))\n        submissions = r.subreddit(subreddit).hot(limit=100)\n        for item in tqdm(submissions):\n            print(sentiment)\n            sentiment = submission_sentiment(item.id)\n            stories.append((item.url, item.title, sentiment))\n    for item in stories:\n        yield item\n\n\ndef prepareForNLP(text):\n\n    \"\"\"Summary\n    Tokenizes the input so it can be analysed.\n\n    Args:\n        text (str): The text to be prepared for analysis.\n\n    Returns:\n        list: The tokenized and POS tagged `text`\n    \"\"\"\n\n    # Split up the input into sentences\n    sentences = nltk.sent_tokenize(text)\n    # Split up the sentences into words\n    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n    # Tokenize the words\n    sentences = [nltk.pos_tag(sent) for sent in sentences]\n    # Return the split and tokenized sentences\n    return sentences\n\n\ndef chunk(sentence):\n\n    \"\"\"Summary\n    Extract the entities from `sentence`\n\n    Args:\n        sentence (list): Sentence to be chunked. Must be in the form of the output of `prepareForNLP`\n\n    Returns:\n        str: Entity in the input sentence\n    \"\"\"\n\n    # Chunking pattern\n    chunkToExtract = \"\"\"\n    NP: {<NNP>*}\"\"\"\n    # Create the new parser\n    parser = nltk.RegexpParser(chunkToExtract)\n    # Parse the text\n    result = parser.parse(sentence)\n    # Yield the proper noun phrases\n    for subtree in result.subtrees():\n        if subtree.label() == 'NP':\n            t = subtree\n            t = ' '.join(word for word, pos in t.leaves())\n            yield t\n\n\n# Yields the keywords (NNPs) from the input as tuples\ndef keywords(text):\n\n    \"\"\"Summary\n    Yields the key entities of `text`.\n\n    Args:\n        text (str): The text that the keywords shall be extracted from.\n\n    Returns:\n        str: Entity from `text`\n    \"\"\"\n\n    sentences = prepareForNLP(text)\n    for sentence in sentences:\n        for kw in chunk(sentence):\n            yield kw\n\n\ndef makeEdges(nodes, story):\n\n    \"\"\"Summary\n    Generate the edges on the graph.\n    \n    Args:\n        nodes (list): List of Node objects generated by `addStory`\n        story (list): List of Story objects generated by `addStory`\n    \"\"\"\n\n    while True:\n        if len(nodes) > 0:\n            node = nodes[0]\n            nodes.remove(node)\n            for i in nodes:\n                edge = Edge(source=story, origin=node, destination=i)\n                edge.save()\n        else:\n            break\n\n\ndef addStory(story):\n\n    \"\"\"Summary\n    \n    \n    Args:\n        story (TYPE): Description\n    \n    Returns:\n        TYPE: Description\n    \"\"\"\n\n    print(\"Adding story:\", story[0])\n    s = Story(source=story[0], content=story[1])\n    s.save()\n    nodes = []\n    for kw in keywords(story[1]):\n        kw = kw.translate(str.maketrans('', '', string.punctuation))\n        if len(Node.objects.filter(name=kw)) < 1:\n            node = Node(name=kw, date=timezone.now(), collectedFrom=s)\n            node.save()\n        else:\n            node = Node.objects.filter(name=kw)[0]\n            node.date = timezone.now()\n        node_sentiment = Sentiment(sentiment=story[2], node=node)\n        node_sentiment.save()\n        nodes.append(node)\n    makeEdges(nodes, story[0])\n\n\n# Updates the DB to a more recent version of the news\ndef updateDB():\n\n    \"\"\"Summary\n    \n    Returns:\n        TYPE: Description\n    \"\"\"\n\n    # For each story currently on the BBC RSS feed\n    for story in stories():\n        # More than 0 if the story is in the DB\n        matches = Story.objects.filter(source=story[0])\n        # If the story isn't in the database\n        if len(matches) == 0:\n            addStory(story)\n        else:\n            pass\n\n\nif __name__ == \"__main__\":\n    print(\"Updating DB\")\n    updateDB()\n",
			"file": "src/updateDB.py",
			"file_size": 5775,
			"file_write_time": 131311463969616770,
			"settings":
			{
				"buffer_size": 5710,
				"line_ending": "Windows"
			}
		},
		{
			"contents": ".. News-Graph documentation master file, created by\n   sphinx-quickstart on Thu Feb  9 20:57:38 2017.\n   You can adapt this file completely to your liking, but it should at least\n   contain the root `toctree` directive.\n\nWelcome to News-Graph's documentation!\n======================================\n\n.. toctree::\n   :maxdepth: 2\n   :caption: Contents:\n\nThis is the documentation of my A-Level project: News-Graph\n\nIndices and tables\n==================\n\n* :ref:`genindex`\n* :ref:`modindex`\n* :ref:`search`\n",
			"file": "src/index.rst",
			"file_size": 525,
			"file_write_time": 131311475316173842,
			"settings":
			{
				"buffer_size": 505,
				"encoding": "UTF-8",
				"line_ending": "Windows"
			}
		},
		{
			"contents": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# News-Graph documentation build configuration file, created by\n# sphinx-quickstart on Thu Feb  9 20:57:38 2017.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\n# import os\n# import sys\n# sys.path.insert(0, os.path.abspath('.'))\n\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = '1.0'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.\nextensions = ['sphinx.ext.autodoc',\n    'sphinx.ext.coverage',\n    'sphinx.ext.mathjax']\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = ['_templates']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = ['.rst', '.md']\nsource_suffix = '.rst'\n\n# The master toctree document.\nmaster_doc = 'index'\n\n# General information about the project.\nproject = 'News-Graph'\ncopyright = '2017, Miles Budden'\nauthor = 'Miles Budden'\n\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = '1.0'\n# The full version, including alpha/beta/rc tags.\nrelease = '1.0.1'\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set \"language\" from the command line for these cases.\nlanguage = None\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This patterns also effect to html_static_path and html_extra_path\nexclude_patterns = ['_build', 'Thumbs.db', '.DS_Store']\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = 'sphinx'\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = False\n\n\n# -- Options for HTML output ----------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = 'alabaster'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\nhtml_static_path = ['_static']\n\n\n# -- Options for HTMLHelp output ------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = 'News-Graphdoc'\n\n\n# -- Options for LaTeX output ---------------------------------------------\n\nlatex_elements = {\n    # The paper size ('letterpaper' or 'a4paper').\n    #\n    # 'papersize': 'letterpaper',\n\n    # The font size ('10pt', '11pt' or '12pt').\n    #\n    # 'pointsize': '10pt',\n\n    # Additional stuff for the LaTeX preamble.\n    #\n    # 'preamble': '',\n\n    # Latex figure (float) alignment\n    #\n    # 'figure_align': 'htbp',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, 'News-Graph.tex', 'News-Graph Documentation',\n     'Miles Budden', 'manual'),\n]\n\n\n# -- Options for manual page output ---------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, 'news-graph', 'News-Graph Documentation',\n     [author], 1)\n]\n\n\n# -- Options for Texinfo output -------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, 'News-Graph', 'News-Graph Documentation',\n     author, 'News-Graph', 'One line description of project.',\n     'Miscellaneous'),\n]\n\n\n\n",
			"file": "src/conf.py",
			"file_size": 4980,
			"file_write_time": 131311474584145472,
			"settings":
			{
				"buffer_size": 4821,
				"line_ending": "Windows"
			}
		}
	],
	"build_system": "",
	"build_system_choices":
	[
		[
			[
				[
					"Packages/Python/Python.sublime-build",
					""
				],
				[
					"Packages/Python/Python.sublime-build",
					"Syntax Check"
				]
			],
			[
				"Packages/Python/Python.sublime-build",
				""
			]
		]
	],
	"build_varint": "",
	"command_palette":
	{
		"height": 354.0,
		"last_filter": "docs",
		"selected_items":
		[
			[
				"docs",
				"AutoDocstring: All"
			],
			[
				"auto",
				"AutoDocstring: All"
			],
			[
				"au",
				"AutoDocstring: Current"
			],
			[
				"insta",
				"Package Control: Install Package"
			],
			[
				"snake",
				"Snake: Start Game"
			],
			[
				"sna",
				"Snake: Start Game"
			],
			[
				"c++",
				"Set Syntax: C++"
			],
			[
				"pyth",
				"Set Syntax: Python"
			],
			[
				"snippe",
				"Snippet: floatfield"
			],
			[
				"package",
				"Package Control: Remove Package"
			],
			[
				"enab",
				"SublimeLinter: Enable Linting"
			],
			[
				"Snippet: ",
				"Snippet: __magic__"
			],
			[
				"enable lin",
				"SublimeLinter: Disable Linting"
			],
			[
				"disab",
				"SublimeLinter: Disable Linter"
			],
			[
				"inst",
				"Package Control: Install Package"
			],
			[
				"form",
				"CodeFormatter: Format Code"
			],
			[
				"mark",
				"Markdown Preview: Preview in Browser"
			]
		],
		"width": 398.0
	},
	"console":
	{
		"height": 784.0,
		"history":
		[
			"quit()",
			"exit()",
			"exit",
			"nope",
			"'Is this interactive'",
			"print('This is pretty cool')",
			"import this",
			"import urllib.request,os,hashlib; h = '2915d1851351e5ee549c20394736b442' + '8bc59f460fa1548d1514676163dafc88'; pf = 'Package Control.sublime-package'; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); by = urllib.request.urlopen( 'http://packagecontrol.io/' + pf.replace(' ', '%20')).read(); dh = hashlib.sha256(by).hexdigest(); print('Error validating download (got %s instead of %s), please try manual install' % (dh, h)) if dh != h else open(os.path.join( ipp, pf), 'wb' ).write(by)"
		]
	},
	"distraction_free":
	{
		"menu_visible": false,
		"show_minimap": false,
		"show_open_files": false,
		"show_tabs": false,
		"side_bar_visible": false,
		"status_bar_visible": false
	},
	"expanded_folders":
	[
		"/C/Users/Miles/news-graph",
		"/C/Users/Miles/news-graph/src",
		"/C/Users/Miles/news-graph/src/relationships/templates",
		"/C/Users/Miles/news-graph/src/relationships/templates/relationships",
		"/C/Users/Miles/news-graph/Testing",
		"/C/Users/Miles/news-graph/Testing/naive"
	],
	"file_history":
	[
		"/C/Users/Miles/news-graph/docs/conf.py",
		"/C/Users/Miles/news-graph/src/newsgraph/urls.py",
		"/C/Users/Miles/news-graph/src/relationships/models.py",
		"/C/Users/Miles/news-graph/src/newsgraph/settings.py",
		"/C/Users/Miles/news-graph/src/relationships/templates/relationships/main.html",
		"/C/Users/Miles/news-graph/src/sentiment/naivebayes.py",
		"/C/Users/Miles/news-graph/src/relationships/views.py",
		"/C/Users/Miles/news-graph/src/manage.py",
		"/C/Users/Miles/news-graph/Testing/naive/naivebayes.py",
		"/C/Users/Miles/news-graph/src/mysite/wsgi.py",
		"/C/Users/Miles/news-graph/src/mysite/urls.py",
		"/C/Users/Miles/news-graph/src/mysite/settings.py",
		"/C/Users/Miles/news-graph/src/mysite/apache/wsgi.py",
		"/C/Users/Miles/news-graph/src/mysite/apache/override.py",
		"/C/Users/Miles/news-graph/src/mysite/apache/000-default.conf",
		"/C/Users/Miles/Downloads/export-miless-main-board-1CBwi2.md",
		"/C/Users/Miles/test.txt",
		"/C/Users/Miles/AppData/Roaming/Sublime Text 3/Packages/User/SublimeLinter.sublime-settings",
		"/C/Users/Miles/news-graph/src/relationships/admin.py",
		"/C/Users/Miles/news-graph/Testing/sample.txt",
		"/C/Users/Miles/news-graph/Testing/entityTest.py",
		"/C/Users/Miles/test",
		"/C/Users/Miles/news-graph/news-graph.sublime-project",
		"/C/Users/Miles/news-graph/src/updateDB.py",
		"/C/Users/Miles/news-graph/src/relationships/migrations/__init__.py",
		"/C/Users/Miles/Downloads/LCDemoMatrix/LCDemoMatrix.ino",
		"/C/Users/Miles/news-graph/Testing/naive/reddit.py",
		"/C/Users/Miles/AppData/Roaming/Sublime Text 3/Packages/User/Snippets/cpp_matrix.sublime-snippet",
		"/C/Users/Miles/Documents/Arduino/libraries/NewPing/NewPing.h",
		"/C/Users/Miles/news-graph/README.md",
		"/C/Users/Miles/news-graph/Testing/naive/app.py",
		"/C/Users/Miles/news-graph/Testing/naive/templates/app.py",
		"/C/Users/Miles/news-graph/Testing/naive/templates/index.html",
		"/C/Users/Miles/news-graph/Testing/twitter_cleaned.py",
		"/C/Users/Miles/Downloads/saasassasa.py",
		"/C/Users/Miles/news-graph/Testing/naive/pos.txt",
		"/C/Users/Miles/news-graph/Testing/naive/pos2.txt",
		"/C/Users/Miles/news-graph/Testing/naive/neg2.txt",
		"/C/Users/Miles/news-graph/Testing/naive/prepare.py",
		"/C/Users/Miles/Downloads/install (18).txt",
		"/D/Program Files/cmder/bin/Readme.md",
		"/D/Program Files/cmder/bin/alias.bat",
		"/C/Users/Miles/Documents/voice/audio_transcribe.py",
		"/C/Users/Miles/Documents/voice/words.py",
		"/D/Steam/steamapps/common/Counter-Strike Global Offensive/csgo/cfg/autoexec.cfg",
		"/C/Users/Miles/Documents/DockerTest/entry.sh",
		"/C/Users/Miles/Documents/ModelDB/index.html",
		"/C/Users/Miles/Documents/GitHub/bulk-installer/installer/serve/chocoCMD",
		"/C/Users/Miles/Documents/cs1v1/src/lobby/urls.py",
		"/C/Users/Miles/Documents/cs1v1/src/lobby/views.py",
		"/C/Windows/System32/RazerCoinstaller.dll",
		"/C/Users/Miles/Documents/phonegap/Test/plugins/cordova-plugin-dialogs/README.md",
		"/C/Users/Miles/Documents/phonegap/Test/plugins/cordova-plugin-camera/README.md",
		"/C/Users/Miles/.ssh/miles",
		"/C/Users/Miles/Documents/DockerTest/hello_django/hello/settings.py",
		"/C/Users/Miles/Documents/DockerTest/Dockerfile",
		"/C/Users/Miles/Documents/DockerTest/hello_django/Dockerfile",
		"/C/Users/Miles/Documents/DockerTest/hello_django/entry.sh",
		"/C/Users/Miles/Documents/ModelDB/css/style.css",
		"/D/Program Files/Sublime Text 3/sublime_plugin.py",
		"/D/VMs/ubuntu.vdi",
		"/C/Users/Miles/Documents/website/index.html",
		"/C/Users/Miles/Documents/website/js/init.js",
		"/C/Users/Miles/Downloads/mat/materialize-src/sass/components/_color.scss",
		"/C/Users/Miles/Downloads/school-intranet/index.html",
		"/C/Users/Miles/Downloads/school-intranet/css/materialize.min.css",
		"/C/Users/Miles/Downloads/mat/materialize-src/sass/materialize.css",
		"/C/Users/Miles/Downloads/mat/materialize-src/sass/components/_variables.scss",
		"/C/Users/Miles/Downloads/mat/materialize-src/sass/materialize.scss",
		"/C/Users/Miles/Documents/website/css/main.css",
		"/C/Users/Miles/AppData/Roaming/Sublime Text 3/Packages/CodeFormatter/CodeFormatter.sublime-settings",
		"/C/Users/Miles/AppData/Local/Temp/scp53218/var/www/html/Sites/Intranet/index.html",
		"/C/Users/Miles/AppData/Roaming/Sublime Text 3/Packages/User/Default (Windows).sublime-keymap",
		"/C/Users/Miles/AppData/Local/Temp/scp46218/var/www/html/Sites/Intranet/index.html",
		"/C/Users/Miles/AppData/Roaming/Sublime Text 3/Packages/Emmet/Emmet.sublime-settings",
		"/C/Users/Miles/Documents/GitHubVisualStudio/news-graph/Testing/twitter_cleaned.py",
		"/D/Steam/steamapps/common/Counter-Strike Global Offensive/bin/(failed)hammer_20160312_210018_2_x0018DF04.mdmp",
		"/D/Steam/steamapps/common/Counter-Strike Global Offensive/bin/vbsp_20160117_211151_1_x009BDD88.mdmp",
		"/D/Steam/steamapps/common/Counter-Strike Global Offensive/bin/csgo.fgd",
		"/D/Steam/steamapps/common/Counter-Strike Global Offensive/bin/GameConfig.txt",
		"/C/Users/Miles/Documents/GitHub/pbexe.github.io/projects.html",
		"/C/Users/Miles/Downloads/mdl/styles.css",
		"/C/Users/Miles/Documents/GitHub/pbexe.github.io/contact.html",
		"/D/Steam/steamapps/common/Counter-Strike Global Offensive/bin/(failed)hammer_20160312_210018_1_x0018DF04.mdmp",
		"/C/Users/Miles/AppData/Local/Temp/scp00207/home/miles/nltk_data/corpora/wordnet/data.noun",
		"/C/Users/Miles/AppData/Local/Temp/7zOC36DE0E0/config.cfg",
		"/C/Users/Miles/AppData/Local/Temp/7zOC36DBDE0/autoexec.cfg",
		"/C/Users/Miles/AppData/Local/Temp/7zO0A0B511F/config.cfg",
		"/C/Users/Miles/Google Drive/autoexec.cfg",
		"/C/Users/Miles/Documents/GitHub/cash-machine/Cash-MachineWPF/Cash-MachineWPF/Views/Actions.xaml",
		"/C/Users/Miles/Documents/GitHub/cash-machine/Cash-MachineWPF/Cash-MachineWPF/Views/WithdrawOther.xaml.cs",
		"/C/Users/Miles/Documents/GitHub/cash-machine/Cash-MachineWPF/Cash-MachineWPF/README.md",
		"/C/Users/Miles/AppData/Local/Temp/7zO87EE03F2/Miles Budden.json",
		"/C/Users/Miles/AppData/Local/Temp/7zO87E62FC3/milesbudden4@gmail.com.ics",
		"/C/Users/Miles/AppData/Roaming/Sublime Text 3/Packages/User/Distraction Free.sublime-settings",
		"/C/Users/Miles/AppData/Roaming/Sublime Text 3/Packages/User/JSON.sublime-settings",
		"/C/Users/Miles/AppData/Roaming/Sublime Text 3/Packages/User/Preferences.sublime-settings",
		"/C/Users/Miles/AppData/Roaming/Sublime Text 3/Packages/Default/Preferences.sublime-settings"
	],
	"find":
	{
		"height": 70.0
	},
	"find_in_files":
	{
		"height": 158.0,
		"where_history":
		[
			"."
		]
	},
	"find_state":
	{
		"case_sensitive": false,
		"find_history":
		[
			"mysite",
			"admin.site.register(Story)",
			" pin ",
			"byte",
			"byte quarter[8]=     {0x41,0x42,0x44,0x48,0x15,0x25,0x47,0x81};\n",
			"stop_words",
			"lex",
			"lexicon",
			"lex",
			"https://hd.unsplash.com",
			"https",
			"nav",
			"C:\\Program Files (x86)",
			"success"
		],
		"highlight": true,
		"in_selection": false,
		"preserve_case": false,
		"regex": false,
		"replace_history":
		[
			"newsgraph",
			"lex",
			"lexicon",
			"D:"
		],
		"reverse": false,
		"show_context": true,
		"use_buffer2": true,
		"whole_word": false,
		"wrap": true
	},
	"groups":
	[
		{
			"selected": 1,
			"sheets":
			[
				{
					"buffer": 0,
					"file": "src/updateDB.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 5710,
						"regions":
						{
						},
						"selection":
						[
							[
								4460,
								4460
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.sublime-syntax",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 2856.0,
						"zoom_level": 1.0
					},
					"stack_index": 2,
					"type": "text"
				},
				{
					"buffer": 1,
					"file": "src/index.rst",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 505,
						"regions":
						{
						},
						"selection":
						[
							[
								505,
								505
							]
						],
						"settings":
						{
							"syntax": "Packages/RestructuredText/reStructuredText.sublime-syntax"
						},
						"translation.x": 0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 0,
					"type": "text"
				},
				{
					"buffer": 2,
					"file": "src/conf.py",
					"semi_transient": true,
					"settings":
					{
						"buffer_size": 4821,
						"regions":
						{
						},
						"selection":
						[
							[
								372,
								372
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.sublime-syntax",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 1,
					"type": "text"
				}
			]
		}
	],
	"incremental_find":
	{
		"height": 32.0
	},
	"input":
	{
		"height": 66.0
	},
	"layout":
	{
		"cells":
		[
			[
				0,
				0,
				1,
				1
			]
		],
		"cols":
		[
			0.0,
			1.0
		],
		"rows":
		[
			0.0,
			1.0
		]
	},
	"menu_visible": true,
	"output.exec":
	{
		"height": 168.0
	},
	"output.find_results":
	{
		"height": 0.0
	},
	"output.unsaved_changes":
	{
		"height": 180.0
	},
	"pinned_build_system": "",
	"project": "news-graph.sublime-project",
	"replace":
	{
		"height": 114.0
	},
	"save_all_on_build": true,
	"select_file":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
			[
				"up",
				"src\\updateDB.py"
			]
		],
		"width": 0.0
	},
	"select_project":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
		],
		"width": 0.0
	},
	"select_symbol":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
		],
		"width": 0.0
	},
	"selected_group": 0,
	"settings":
	{
	},
	"show_minimap": true,
	"show_open_files": false,
	"show_tabs": true,
	"side_bar_visible": true,
	"side_bar_width": 203.0,
	"status_bar_visible": true,
	"template_settings":
	{
	}
}
